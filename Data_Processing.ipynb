{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6882a949",
   "metadata": {},
   "source": [
    "# Network Security Data Processing: 4Network, UNSW-NB15, and CESNET-TimeSeries24\n",
    "\n",
    "This notebook implements the data processing pipeline for the AI4Cyber assignment. The goal is to load, clean, preprocess, and merge three distinct network security datasets into a unified format suitable for training various machine learning models (classification, clustering, and time-series forecasting).\n",
    "\n",
    "The three datasets are:\n",
    "1.  **4Network**: The basic dataset provided in the assignment.\n",
    "2.  **UNSW-NB15**: A comprehensive, modern network intrusion dataset.\n",
    "3.  **CESNET-TimeSeries24**: A time-series dataset of network traffic per IP address."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0ce4f7",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Define Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "729b5671",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Define paths to the datasets\n",
    "# It's good practice to use relative paths if the notebook is in the project root,\n",
    "# but here we use absolute paths for clarity.\n",
    "BASE_PATH = \"e:/Swinburne_bsc_data_science/year_two/sem_two/COS30049/Assignment2\"\n",
    "\n",
    "PATH_4NETWORK = os.path.join(BASE_PATH, \"Assignment Datasets/Assignment Datasets/4Network\")\n",
    "PATH_UNSW_NB15 = os.path.join(BASE_PATH, \"UNSW-NB15/CSV Files\")\n",
    "PATH_CESNET = os.path.join(BASE_PATH, \"ip_addresses_sample/ip_addresses_sample\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b670728",
   "metadata": {},
   "source": [
    "## 2. Load and Preprocess UNSW-NB15 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9af0be4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original UNSW-NB15 attack categories:\n",
      "['Normal' 'Backdoor' 'Analysis' 'Fuzzers' 'Shellcode' 'Reconnaissance'\n",
      " 'Exploits' 'DoS' 'Worms' 'Generic']\n",
      "\n",
      "Processed UNSW-NB15 DataFrame head:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dur</th>\n",
       "      <th>proto</th>\n",
       "      <th>service</th>\n",
       "      <th>state</th>\n",
       "      <th>spkts</th>\n",
       "      <th>dpkts</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>rate</th>\n",
       "      <th>sttl</th>\n",
       "      <th>...</th>\n",
       "      <th>is_ftp_login</th>\n",
       "      <th>ct_ftp_cmd</th>\n",
       "      <th>ct_flw_http_mthd</th>\n",
       "      <th>ct_src_ltm</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "      <th>is_sm_ips_ports</th>\n",
       "      <th>attack_cat</th>\n",
       "      <th>label</th>\n",
       "      <th>category</th>\n",
       "      <th>binary_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.121478</td>\n",
       "      <td>tcp</td>\n",
       "      <td>-</td>\n",
       "      <td>FIN</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>258</td>\n",
       "      <td>172</td>\n",
       "      <td>74.087490</td>\n",
       "      <td>252</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.649902</td>\n",
       "      <td>tcp</td>\n",
       "      <td>-</td>\n",
       "      <td>FIN</td>\n",
       "      <td>14</td>\n",
       "      <td>38</td>\n",
       "      <td>734</td>\n",
       "      <td>42014</td>\n",
       "      <td>78.473372</td>\n",
       "      <td>62</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.623129</td>\n",
       "      <td>tcp</td>\n",
       "      <td>-</td>\n",
       "      <td>FIN</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>364</td>\n",
       "      <td>13186</td>\n",
       "      <td>14.170161</td>\n",
       "      <td>62</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.681642</td>\n",
       "      <td>tcp</td>\n",
       "      <td>ftp</td>\n",
       "      <td>FIN</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>628</td>\n",
       "      <td>770</td>\n",
       "      <td>13.677108</td>\n",
       "      <td>62</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.449454</td>\n",
       "      <td>tcp</td>\n",
       "      <td>-</td>\n",
       "      <td>FIN</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>534</td>\n",
       "      <td>268</td>\n",
       "      <td>33.373826</td>\n",
       "      <td>254</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        dur proto service state  spkts  dpkts  sbytes  dbytes       rate  \\\n",
       "0  0.121478   tcp       -   FIN      6      4     258     172  74.087490   \n",
       "1  0.649902   tcp       -   FIN     14     38     734   42014  78.473372   \n",
       "2  1.623129   tcp       -   FIN      8     16     364   13186  14.170161   \n",
       "3  1.681642   tcp     ftp   FIN     12     12     628     770  13.677108   \n",
       "4  0.449454   tcp       -   FIN     10      6     534     268  33.373826   \n",
       "\n",
       "   sttl  ...  is_ftp_login  ct_ftp_cmd  ct_flw_http_mthd  ct_src_ltm  \\\n",
       "0   252  ...             0           0                 0           1   \n",
       "1    62  ...             0           0                 0           1   \n",
       "2    62  ...             0           0                 0           2   \n",
       "3    62  ...             1           1                 0           2   \n",
       "4   254  ...             0           0                 0           2   \n",
       "\n",
       "   ct_srv_dst  is_sm_ips_ports  attack_cat  label  category  binary_label  \n",
       "0           1                0      Normal      0    Normal             0  \n",
       "1           6                0      Normal      0    Normal             0  \n",
       "2           6                0      Normal      0    Normal             0  \n",
       "3           1                0      Normal      0    Normal             0  \n",
       "4          39                0      Normal      0    Normal             0  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load UNSW-NB15 training and testing sets\n",
    "unsw_train_path = os.path.join(BASE_PATH, \"UNSW-NB15/CSV Files/Training and Testing Sets/UNSW_NB15_training-set.csv\")\n",
    "unsw_test_path = os.path.join(BASE_PATH, \"UNSW-NB15/CSV Files/Training and Testing Sets/UNSW_NB15_testing-set.csv\")\n",
    "\n",
    "df_unsw_train = pd.read_csv(unsw_train_path)\n",
    "df_unsw_test = pd.read_csv(unsw_test_path)\n",
    "\n",
    "# Concatenate them\n",
    "df_unsw = pd.concat([df_unsw_train, df_unsw_test], ignore_index=True)\n",
    "\n",
    "# Drop irrelevant columns (like id)\n",
    "df_unsw = df_unsw.drop(columns=['id'])\n",
    "\n",
    "# Rename columns for clarity and consistency\n",
    "df_unsw.columns = df_unsw.columns.str.strip().str.lower().str.replace(' ', '_')\n",
    "\n",
    "# Map attack categories to a simplified set\n",
    "# First, let's see the original categories\n",
    "print(\"Original UNSW-NB15 attack categories:\")\n",
    "print(df_unsw['attack_cat'].unique())\n",
    "\n",
    "# Define a mapping to the 4 main categories + Normal\n",
    "attack_map = {\n",
    "    'Normal': 'Normal',\n",
    "    'Generic': 'DoS',\n",
    "    'Exploits': 'Probe',\n",
    "    'Fuzzers': 'Probe',\n",
    "    'DoS': 'DoS',\n",
    "    'Reconnaissance': 'Probe',\n",
    "    'Analysis': 'Probe',\n",
    "    'Backdoor': 'R2L',\n",
    "    'Shellcode': 'U2R',\n",
    "    'Worms': 'U2R',\n",
    "    # Handle potential NaN or other unexpected values\n",
    "    np.nan: 'Normal' \n",
    "}\n",
    "df_unsw['attack_cat'] = df_unsw['attack_cat'].fillna('Normal')\n",
    "df_unsw['category'] = df_unsw['attack_cat'].apply(lambda x: attack_map.get(x, 'Other'))\n",
    "\n",
    "\n",
    "# Create a binary label (0 for Normal, 1 for Attack)\n",
    "df_unsw['binary_label'] = df_unsw['label'].apply(lambda x: 0 if x == 0 else 1)\n",
    "\n",
    "print(\"\\nProcessed UNSW-NB15 DataFrame head:\")\n",
    "df_unsw.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce7f68d",
   "metadata": {},
   "source": [
    "## 3. Load and Preprocess 4Network Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9cbb7e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original 4Network columns: Index(['duration', 'protocol_type', 'service', 'flag', 'src_bytes',\n",
      "       'dst_bytes', 'count', 'srv_count', 'serror_rate', 'label'],\n",
      "      dtype='object')\n",
      "\n",
      "Processed 4Network DataFrame head:\n",
      "\n",
      "Processed 4Network DataFrame head:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>count</th>\n",
       "      <th>srv_count</th>\n",
       "      <th>serror_rate</th>\n",
       "      <th>attack_cat</th>\n",
       "      <th>category</th>\n",
       "      <th>binary_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>ftp_data</td>\n",
       "      <td>SF</td>\n",
       "      <td>491.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>udp</td>\n",
       "      <td>other</td>\n",
       "      <td>SF</td>\n",
       "      <td>146.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>private</td>\n",
       "      <td>S0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>neptune</td>\n",
       "      <td>DoS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>232.0</td>\n",
       "      <td>8153.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>normal</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>199.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration protocol_type   service flag  sbytes  dbytes  count  srv_count  \\\n",
       "0       0.0           tcp  ftp_data   SF   491.0     0.0    2.0        2.0   \n",
       "1       0.0           udp     other   SF   146.0     0.0   13.0        1.0   \n",
       "2       0.0           tcp   private   S0     0.0     0.0  123.0        6.0   \n",
       "3       0.0           tcp      http   SF   232.0  8153.0    5.0        5.0   \n",
       "4       0.0           tcp      http   SF   199.0   420.0   30.0       32.0   \n",
       "\n",
       "   serror_rate attack_cat category  binary_label  \n",
       "0          0.0     normal   Normal             0  \n",
       "1          0.0     normal   Normal             0  \n",
       "2          1.0    neptune      DoS             1  \n",
       "3          0.2     normal   Normal             0  \n",
       "4          0.0     normal   Normal             0  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the 4Network data and the label map\n",
    "df_4network = pd.read_csv(os.path.join(PATH_4NETWORK, \"basic_data_4.csv\"))\n",
    "print(\"Original 4Network columns:\", df_4network.columns)\n",
    "\n",
    "label_map_4network = pd.read_csv(os.path.join(PATH_4NETWORK, \"label_category_map.csv\"))\n",
    "\n",
    "# Merge to get descriptive category labels\n",
    "df_4network = df_4network.merge(label_map_4network, on='label', how='left')\n",
    "\n",
    "# Rename columns to align with a common schema\n",
    "# Let's aim for a schema similar to UNSW-NB15 where possible\n",
    "df_4network = df_4network.rename(columns={\n",
    "    'src_bytes': 'sbytes',\n",
    "    'dst_bytes': 'dbytes',\n",
    "    'label': 'attack_cat'\n",
    "})\n",
    "\n",
    "# Create a binary label\n",
    "df_4network['binary_label'] = df_4network['category'].apply(lambda x: 0 if x == 'Normal' else 1)\n",
    "\n",
    "print(\"\\nProcessed 4Network DataFrame head:\")\n",
    "df_4network.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604e6f57",
   "metadata": {},
   "source": [
    "## 4. Load and Preprocess CESNET-TimeSeries24 Dataset\n",
    "\n",
    "This dataset is different as it's a time-series of aggregated data per IP, not flow-based like the others. To merge it, we need to transform it into a flow-like summary. We'll aggregate features for each IP over the entire period available in the `agg_1_day` files. This simulates having a summary of each IP's behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8f9c527c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed and Aggregated CESNET DataFrame head:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>n_bytes_mean</th>\n",
       "      <th>n_bytes_std</th>\n",
       "      <th>n_bytes_max</th>\n",
       "      <th>n_packets_mean</th>\n",
       "      <th>n_packets_std</th>\n",
       "      <th>n_packets_max</th>\n",
       "      <th>n_flows_mean</th>\n",
       "      <th>n_flows_std</th>\n",
       "      <th>n_flows_max</th>\n",
       "      <th>avg_duration_mean</th>\n",
       "      <th>category</th>\n",
       "      <th>binary_label</th>\n",
       "      <th>attack_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>7.858580e+08</td>\n",
       "      <td>4.513904e+08</td>\n",
       "      <td>5080981875</td>\n",
       "      <td>1.032196e+07</td>\n",
       "      <td>5.944051e+06</td>\n",
       "      <td>66857421</td>\n",
       "      <td>3.978649e+06</td>\n",
       "      <td>928629.599686</td>\n",
       "      <td>7243129</td>\n",
       "      <td>5.120036</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>1.548272e+07</td>\n",
       "      <td>5.377649e+07</td>\n",
       "      <td>893080618</td>\n",
       "      <td>3.078340e+04</td>\n",
       "      <td>4.308937e+04</td>\n",
       "      <td>698501</td>\n",
       "      <td>1.079593e+03</td>\n",
       "      <td>726.229250</td>\n",
       "      <td>7999</td>\n",
       "      <td>49.034357</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>2.168300e+07</td>\n",
       "      <td>3.079153e+07</td>\n",
       "      <td>195103149</td>\n",
       "      <td>2.720752e+04</td>\n",
       "      <td>3.204526e+04</td>\n",
       "      <td>212731</td>\n",
       "      <td>3.037066e+02</td>\n",
       "      <td>95.100157</td>\n",
       "      <td>564</td>\n",
       "      <td>58.303892</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103</td>\n",
       "      <td>6.927059e+10</td>\n",
       "      <td>4.213953e+10</td>\n",
       "      <td>192280591577</td>\n",
       "      <td>7.134487e+07</td>\n",
       "      <td>4.417919e+07</td>\n",
       "      <td>197611735</td>\n",
       "      <td>5.124451e+05</td>\n",
       "      <td>355795.646864</td>\n",
       "      <td>1407589</td>\n",
       "      <td>24.954857</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>118</td>\n",
       "      <td>1.269615e+10</td>\n",
       "      <td>6.955015e+09</td>\n",
       "      <td>31446730432</td>\n",
       "      <td>1.288592e+07</td>\n",
       "      <td>7.197750e+06</td>\n",
       "      <td>32375299</td>\n",
       "      <td>6.011918e+04</td>\n",
       "      <td>37757.047161</td>\n",
       "      <td>163934</td>\n",
       "      <td>27.084036</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  n_bytes_mean   n_bytes_std   n_bytes_max  n_packets_mean  \\\n",
       "0   11  7.858580e+08  4.513904e+08    5080981875    1.032196e+07   \n",
       "1   20  1.548272e+07  5.377649e+07     893080618    3.078340e+04   \n",
       "2  101  2.168300e+07  3.079153e+07     195103149    2.720752e+04   \n",
       "3  103  6.927059e+10  4.213953e+10  192280591577    7.134487e+07   \n",
       "4  118  1.269615e+10  6.955015e+09   31446730432    1.288592e+07   \n",
       "\n",
       "   n_packets_std  n_packets_max  n_flows_mean    n_flows_std  n_flows_max  \\\n",
       "0   5.944051e+06       66857421  3.978649e+06  928629.599686      7243129   \n",
       "1   4.308937e+04         698501  1.079593e+03     726.229250         7999   \n",
       "2   3.204526e+04         212731  3.037066e+02      95.100157          564   \n",
       "3   4.417919e+07      197611735  5.124451e+05  355795.646864      1407589   \n",
       "4   7.197750e+06       32375299  6.011918e+04   37757.047161       163934   \n",
       "\n",
       "   avg_duration_mean category  binary_label attack_cat  \n",
       "0           5.120036   Normal             0     normal  \n",
       "1          49.034357   Normal             0     normal  \n",
       "2          58.303892   Normal             0     normal  \n",
       "3          24.954857   Normal             0     normal  \n",
       "4          27.084036   Normal             0     normal  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and concatenate all daily aggregation files\n",
    "agg_files_path = os.path.join(PATH_CESNET, \"agg_1_day/*.csv\")\n",
    "all_files = glob.glob(agg_files_path)\n",
    "\n",
    "df_list = []\n",
    "for filename in all_files:\n",
    "    df_file = pd.read_csv(filename)\n",
    "    # Extract the ID from the filename, which is the unique identifier for a source.\n",
    "    file_id = os.path.basename(filename).split('.')[0]\n",
    "    df_file['id'] = int(file_id)\n",
    "    df_list.append(df_file)\n",
    "\n",
    "df_cesnet_raw = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# The 'identifiers.csv' file does not contain IP addresses, so we will not use it.\n",
    "# We will group by the 'id' which uniquely identifies each entity.\n",
    "\n",
    "# This dataset doesn't have attack labels. We'll treat it as 'Normal' for now.\n",
    "df_cesnet_raw['category'] = 'Normal'\n",
    "df_cesnet_raw['binary_label'] = 0\n",
    "df_cesnet_raw['attack_cat'] = 'normal'\n",
    "\n",
    "# To make it compatible, we need to aggregate it to a \"flow-like\" summary per ID.\n",
    "# We will calculate mean, std, max for the numerical features for each ID.\n",
    "agg_dict = {\n",
    "    'n_bytes': ['mean', 'std', 'max'],\n",
    "    'n_packets': ['mean', 'std', 'max'],\n",
    "    'n_flows': ['mean', 'std', 'max'],\n",
    "    'avg_duration': ['mean']\n",
    "}\n",
    "\n",
    "# Check which of the desired aggregation keys are present in the dataframe\n",
    "agg_keys_to_use = {k: v for k, v in agg_dict.items() if k in df_cesnet_raw.columns}\n",
    "\n",
    "# CORRECTED: Group by 'id' as it is the unique identifier.\n",
    "df_cesnet_agg = df_cesnet_raw.groupby('id').agg(agg_keys_to_use).reset_index()\n",
    "\n",
    "# Flatten the multi-level column names\n",
    "df_cesnet_agg.columns = ['_'.join(col).strip() for col in df_cesnet_agg.columns.values]\n",
    "df_cesnet_agg = df_cesnet_agg.rename(columns={'id_': 'id'})\n",
    "\n",
    "# Add the labels back\n",
    "df_cesnet_agg['category'] = 'Normal'\n",
    "df_cesnet_agg['binary_label'] = 0\n",
    "df_cesnet_agg['attack_cat'] = 'normal'\n",
    "\n",
    "print(\"\\nProcessed and Aggregated CESNET DataFrame head:\")\n",
    "df_cesnet_agg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b11053d",
   "metadata": {},
   "source": [
    "## 5. Harmonize and Merge Datasets\n",
    "\n",
    "Now, we'll identify common features and create a unified schema to merge the three datasets. This is a critical step and involves making decisions about which features to keep, which to discard, and how to align them.\n",
    "\n",
    "**Common Schema:**\n",
    "We will define a common set of columns. If a dataset doesn't have a particular column, it will be filled with NaN or a sensible default (example like 0).\n",
    "\n",
    "- `duration`: Connection duration.\n",
    "- `proto`: Protocol.\n",
    "- `service`: Service type.\n",
    "- `state` or `flag`: Connection state.\n",
    "- `sbytes`, `dbytes`: Source and destination bytes.\n",
    "- `spkts`, `dpkts`: Source and destination packets.\n",
    "- `srate`, `drate`: Source and destination packet rates.\n",
    "- `category`: The multi-class label (Normal, DoS, Probe, etc.).\n",
    "- `binary_label`: The binary label (0 or 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cf3aa347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the merged dataframe: (283865, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>spkts</th>\n",
       "      <th>dpkts</th>\n",
       "      <th>category</th>\n",
       "      <th>binary_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.121478</td>\n",
       "      <td>tcp</td>\n",
       "      <td>-</td>\n",
       "      <td>FIN</td>\n",
       "      <td>258.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.649902</td>\n",
       "      <td>tcp</td>\n",
       "      <td>-</td>\n",
       "      <td>FIN</td>\n",
       "      <td>734.0</td>\n",
       "      <td>42014.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.623129</td>\n",
       "      <td>tcp</td>\n",
       "      <td>-</td>\n",
       "      <td>FIN</td>\n",
       "      <td>364.0</td>\n",
       "      <td>13186.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.681642</td>\n",
       "      <td>tcp</td>\n",
       "      <td>ftp</td>\n",
       "      <td>FIN</td>\n",
       "      <td>628.0</td>\n",
       "      <td>770.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.449454</td>\n",
       "      <td>tcp</td>\n",
       "      <td>-</td>\n",
       "      <td>FIN</td>\n",
       "      <td>534.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration protocol service flag  sbytes   dbytes  spkts  dpkts category  \\\n",
       "0  0.121478      tcp       -  FIN   258.0    172.0    6.0    4.0   Normal   \n",
       "1  0.649902      tcp       -  FIN   734.0  42014.0   14.0   38.0   Normal   \n",
       "2  1.623129      tcp       -  FIN   364.0  13186.0    8.0   16.0   Normal   \n",
       "3  1.681642      tcp     ftp  FIN   628.0    770.0   12.0   12.0   Normal   \n",
       "4  0.449454      tcp       -  FIN   534.0    268.0   10.0    6.0   Normal   \n",
       "\n",
       "   binary_label  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Harmonize UNSW-NB15\n",
    "df_unsw_h = df_unsw.rename(columns={\n",
    "    'dur': 'duration',\n",
    "    'spkts': 'spkts',\n",
    "    'dpkts': 'dpkts',\n",
    "    'sbytes': 'sbytes',\n",
    "    'dbytes': 'dbytes',\n",
    "    'proto': 'protocol',\n",
    "    'state': 'flag'\n",
    "})\n",
    "\n",
    "# Harmonize 4Network\n",
    "# CORRECTED: 'protocol_type' is the correct original column name.\n",
    "df_4network_h = df_4network.rename(columns={\n",
    "    'duration': 'duration',\n",
    "    'protocol_type': 'protocol', # <-- FIX\n",
    "    'service': 'service',\n",
    "    'flag': 'flag',\n",
    "    'sbytes': 'sbytes',\n",
    "    'dbytes': 'dbytes'\n",
    "})\n",
    "# Add missing packet columns to 4Network\n",
    "df_4network_h['spkts'] = 0\n",
    "df_4network_h['dpkts'] = 0\n",
    "\n",
    "\n",
    "# Harmonize CESNET - mapping aggregated stats to the common schema.\n",
    "df_cesnet_h = pd.DataFrame()\n",
    "# We use the aggregated 'mean' values as representatives for the flow.\n",
    "df_cesnet_h['sbytes'] = df_cesnet_agg['n_bytes_mean'] \n",
    "df_cesnet_h['dbytes'] = df_cesnet_agg['n_bytes_mean'] # Assuming symmetric traffic for this dataset\n",
    "df_cesnet_h['spkts'] = df_cesnet_agg['n_packets_mean']\n",
    "df_cesnet_h['dpkts'] = df_cesnet_agg['n_packets_mean'] # Assuming symmetric traffic\n",
    "df_cesnet_h['duration'] = df_cesnet_agg['avg_duration_mean']\n",
    "df_cesnet_h['protocol'] = 'udp' # Placeholder\n",
    "df_cesnet_h['service'] = 'dns'  # Placeholder\n",
    "df_cesnet_h['flag'] = 'CON'    # Placeholder\n",
    "df_cesnet_h['category'] = 'Normal'\n",
    "df_cesnet_h['binary_label'] = 0\n",
    "\n",
    "\n",
    "# Define common columns for the final merge\n",
    "common_cols = ['duration', 'protocol', 'service', 'flag', 'sbytes', 'dbytes', 'spkts', 'dpkts', 'category', 'binary_label']\n",
    "\n",
    "# Select and reorder columns for all dataframes\n",
    "df_unsw_final = df_unsw_h[common_cols]\n",
    "df_4network_final = df_4network_h[common_cols]\n",
    "df_cesnet_final = df_cesnet_h[common_cols]\n",
    "\n",
    "# Concatenate all three dataframes\n",
    "df_merged = pd.concat([df_unsw_final, df_4network_final, df_cesnet_final], ignore_index=True)\n",
    "\n",
    "print(\"Shape of the merged dataframe:\", df_merged.shape)\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811a6965",
   "metadata": {},
   "source": [
    "## 6. Feature Engineering\n",
    "\n",
    "Now that we have a merged dataset, we can create new features that might help the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9aeffc53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame with new features:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>spkts</th>\n",
       "      <th>dpkts</th>\n",
       "      <th>category</th>\n",
       "      <th>binary_label</th>\n",
       "      <th>srate</th>\n",
       "      <th>drate</th>\n",
       "      <th>total_bytes</th>\n",
       "      <th>total_pkts</th>\n",
       "      <th>bytes_per_pkt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.121478</td>\n",
       "      <td>tcp</td>\n",
       "      <td>-</td>\n",
       "      <td>FIN</td>\n",
       "      <td>258.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "      <td>49.391253</td>\n",
       "      <td>32.927502</td>\n",
       "      <td>430.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>42.999996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.649902</td>\n",
       "      <td>tcp</td>\n",
       "      <td>-</td>\n",
       "      <td>FIN</td>\n",
       "      <td>734.0</td>\n",
       "      <td>42014.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "      <td>21.541676</td>\n",
       "      <td>58.470264</td>\n",
       "      <td>42748.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>822.076907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.623129</td>\n",
       "      <td>tcp</td>\n",
       "      <td>-</td>\n",
       "      <td>FIN</td>\n",
       "      <td>364.0</td>\n",
       "      <td>13186.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "      <td>4.928749</td>\n",
       "      <td>9.857498</td>\n",
       "      <td>13550.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>564.583310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.681642</td>\n",
       "      <td>tcp</td>\n",
       "      <td>ftp</td>\n",
       "      <td>FIN</td>\n",
       "      <td>628.0</td>\n",
       "      <td>770.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "      <td>7.135878</td>\n",
       "      <td>7.135878</td>\n",
       "      <td>1398.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>58.249998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.449454</td>\n",
       "      <td>tcp</td>\n",
       "      <td>-</td>\n",
       "      <td>FIN</td>\n",
       "      <td>534.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "      <td>22.249168</td>\n",
       "      <td>13.349501</td>\n",
       "      <td>802.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>50.124997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration protocol service flag  sbytes   dbytes  spkts  dpkts category  \\\n",
       "0  0.121478      tcp       -  FIN   258.0    172.0    6.0    4.0   Normal   \n",
       "1  0.649902      tcp       -  FIN   734.0  42014.0   14.0   38.0   Normal   \n",
       "2  1.623129      tcp       -  FIN   364.0  13186.0    8.0   16.0   Normal   \n",
       "3  1.681642      tcp     ftp  FIN   628.0    770.0   12.0   12.0   Normal   \n",
       "4  0.449454      tcp       -  FIN   534.0    268.0   10.0    6.0   Normal   \n",
       "\n",
       "   binary_label      srate      drate  total_bytes  total_pkts  bytes_per_pkt  \n",
       "0             0  49.391253  32.927502        430.0        10.0      42.999996  \n",
       "1             0  21.541676  58.470264      42748.0        52.0     822.076907  \n",
       "2             0   4.928749   9.857498      13550.0        24.0     564.583310  \n",
       "3             0   7.135878   7.135878       1398.0        24.0      58.249998  \n",
       "4             0  22.249168  13.349501        802.0        16.0      50.124997  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Avoid division by zero for rates\n",
    "epsilon = 1e-6\n",
    "\n",
    "df_merged['srate'] = df_merged['spkts'] / (df_merged['duration'] + epsilon)\n",
    "df_merged['drate'] = df_merged['dpkts'] / (df_merged['duration'] + epsilon)\n",
    "df_merged['total_bytes'] = df_merged['sbytes'] + df_merged['dbytes']\n",
    "df_merged['total_pkts'] = df_merged['spkts'] + df_merged['dpkts']\n",
    "df_merged['bytes_per_pkt'] = df_merged['total_bytes'] / (df_merged['total_pkts'] + epsilon)\n",
    "\n",
    "print(\"Merged DataFrame with new features:\")\n",
    "df_merged.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5645c24b",
   "metadata": {},
   "source": [
    "## 7. Data Cleaning and Preprocessing\n",
    "\n",
    "This step involves handling missing values, encoding categorical variables, and scaling numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4b302031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of processed features: (283865, 240)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>spkts</th>\n",
       "      <th>dpkts</th>\n",
       "      <th>srate</th>\n",
       "      <th>drate</th>\n",
       "      <th>total_bytes</th>\n",
       "      <th>total_pkts</th>\n",
       "      <th>bytes_per_pkt</th>\n",
       "      <th>...</th>\n",
       "      <th>flag_RSTOS0</th>\n",
       "      <th>flag_RSTR</th>\n",
       "      <th>flag_S0</th>\n",
       "      <th>flag_S1</th>\n",
       "      <th>flag_S2</th>\n",
       "      <th>flag_S3</th>\n",
       "      <th>flag_SF</th>\n",
       "      <th>flag_SH</th>\n",
       "      <th>flag_URN</th>\n",
       "      <th>flag_no</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.034962</td>\n",
       "      <td>-0.003974</td>\n",
       "      <td>-0.003987</td>\n",
       "      <td>-0.004535</td>\n",
       "      <td>-0.004538</td>\n",
       "      <td>-0.608363</td>\n",
       "      <td>-0.016298</td>\n",
       "      <td>-0.003981</td>\n",
       "      <td>-0.004537</td>\n",
       "      <td>-0.003435</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.034305</td>\n",
       "      <td>-0.003973</td>\n",
       "      <td>-0.003837</td>\n",
       "      <td>-0.004505</td>\n",
       "      <td>-0.004412</td>\n",
       "      <td>-0.608485</td>\n",
       "      <td>-0.015432</td>\n",
       "      <td>-0.003905</td>\n",
       "      <td>-0.004459</td>\n",
       "      <td>-0.003435</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.033096</td>\n",
       "      <td>-0.003974</td>\n",
       "      <td>-0.003940</td>\n",
       "      <td>-0.004528</td>\n",
       "      <td>-0.004494</td>\n",
       "      <td>-0.608557</td>\n",
       "      <td>-0.017079</td>\n",
       "      <td>-0.003957</td>\n",
       "      <td>-0.004511</td>\n",
       "      <td>-0.003435</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.033023</td>\n",
       "      <td>-0.003973</td>\n",
       "      <td>-0.003985</td>\n",
       "      <td>-0.004513</td>\n",
       "      <td>-0.004509</td>\n",
       "      <td>-0.608548</td>\n",
       "      <td>-0.017172</td>\n",
       "      <td>-0.003979</td>\n",
       "      <td>-0.004511</td>\n",
       "      <td>-0.003435</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.034554</td>\n",
       "      <td>-0.003973</td>\n",
       "      <td>-0.003987</td>\n",
       "      <td>-0.004520</td>\n",
       "      <td>-0.004531</td>\n",
       "      <td>-0.608482</td>\n",
       "      <td>-0.016961</td>\n",
       "      <td>-0.003980</td>\n",
       "      <td>-0.004526</td>\n",
       "      <td>-0.003435</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 240 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration    sbytes    dbytes     spkts     dpkts     srate     drate  \\\n",
       "0 -0.034962 -0.003974 -0.003987 -0.004535 -0.004538 -0.608363 -0.016298   \n",
       "1 -0.034305 -0.003973 -0.003837 -0.004505 -0.004412 -0.608485 -0.015432   \n",
       "2 -0.033096 -0.003974 -0.003940 -0.004528 -0.004494 -0.608557 -0.017079   \n",
       "3 -0.033023 -0.003973 -0.003985 -0.004513 -0.004509 -0.608548 -0.017172   \n",
       "4 -0.034554 -0.003973 -0.003987 -0.004520 -0.004531 -0.608482 -0.016961   \n",
       "\n",
       "   total_bytes  total_pkts  bytes_per_pkt  ...  flag_RSTOS0  flag_RSTR  \\\n",
       "0    -0.003981   -0.004537      -0.003435  ...          0.0        0.0   \n",
       "1    -0.003905   -0.004459      -0.003435  ...          0.0        0.0   \n",
       "2    -0.003957   -0.004511      -0.003435  ...          0.0        0.0   \n",
       "3    -0.003979   -0.004511      -0.003435  ...          0.0        0.0   \n",
       "4    -0.003980   -0.004526      -0.003435  ...          0.0        0.0   \n",
       "\n",
       "   flag_S0  flag_S1  flag_S2  flag_S3  flag_SF  flag_SH  flag_URN  flag_no  \n",
       "0      0.0      0.0      0.0      0.0      0.0      0.0       0.0      0.0  \n",
       "1      0.0      0.0      0.0      0.0      0.0      0.0       0.0      0.0  \n",
       "2      0.0      0.0      0.0      0.0      0.0      0.0       0.0      0.0  \n",
       "3      0.0      0.0      0.0      0.0      0.0      0.0       0.0      0.0  \n",
       "4      0.0      0.0      0.0      0.0      0.0      0.0       0.0      0.0  \n",
       "\n",
       "[5 rows x 240 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate features (X) and labels (y)\n",
    "X = df_merged.drop(columns=['category', 'binary_label'])\n",
    "y_multi = df_merged['category']\n",
    "y_binary = df_merged['binary_label']\n",
    "\n",
    "# Identify numerical and categorical columns\n",
    "numerical_cols = X.select_dtypes(include=np.number).columns.tolist()\n",
    "categorical_cols = X.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "# Create preprocessing pipelines for numerical and categorical features\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Create a preprocessor object using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Apply the transformations\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "# The output X_processed is a sparse matrix or numpy array. Let's get the feature names.\n",
    "ohe_feature_names = preprocessor.named_transformers_['cat']['onehot'].get_feature_names_out(categorical_cols)\n",
    "all_feature_names = numerical_cols + list(ohe_feature_names)\n",
    "\n",
    "# Convert the processed data back to a DataFrame for inspection\n",
    "X_processed_df = pd.DataFrame(X_processed.toarray(), columns=all_feature_names)\n",
    "\n",
    "\n",
    "print(\"Shape of processed features:\", X_processed_df.shape)\n",
    "X_processed_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61d4d7f",
   "metadata": {},
   "source": [
    "## 8. Handle Data Imbalance\n",
    "\n",
    "Classification models can be biased towards the majority class. We'll use SMOTE (Synthetic Minority Over-sampling Technique) to balance the dataset. This should only be applied to the training data to avoid data leakage into the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "227e52e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before SMOTE:\n",
      "category\n",
      "Normal    85959\n",
      "Probe     70179\n",
      "DoS       67566\n",
      "R2L        2031\n",
      "U2R        1357\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda3\\Lib\\site-packages\\imblearn\\over_sampling\\_smote\\base.py:370: FutureWarning: The parameter `n_jobs` has been deprecated in 0.10 and will be removed in 0.12. You can pass an nearest neighbors estimator where `n_jobs` is already set instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class distribution after SMOTE:\n",
      "category\n",
      "Normal    85959\n",
      "DoS       85959\n",
      "Probe     85959\n",
      "U2R       85959\n",
      "R2L       85959\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# First, split the data into training and testing sets\n",
    "X_train, X_test, y_train_multi, y_test_multi = train_test_split(\n",
    "    X_processed_df, y_multi, test_size=0.2, random_state=42, stratify=y_multi\n",
    ")\n",
    "\n",
    "# Check the class distribution before SMOTE\n",
    "print(\"Class distribution before SMOTE:\")\n",
    "print(y_train_multi.value_counts())\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "# n_jobs=-1 uses all available CPU cores\n",
    "smote = SMOTE(random_state=42, n_jobs=-1)\n",
    "X_train_smote, y_train_smote_multi = smote.fit_resample(X_train, y_train_multi)\n",
    "\n",
    "# Check the class distribution after SMOTE\n",
    "print(\"\\nClass distribution after SMOTE:\")\n",
    "print(y_train_smote_multi.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fe601e",
   "metadata": {},
   "source": [
    "## 9. Save Processed Data\n",
    "\n",
    "Finally, we save the processed and balanced training data, as well as the untouched test data, to be used in the modeling phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "901aa863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to: e:/Swinburne_bsc_data_science/year_two/sem_two/COS30049/Assignment2\\processed_data\n"
     ]
    }
   ],
   "source": [
    "# Create a directory for processed data if it doesn't exist\n",
    "PROCESSED_DATA_PATH = os.path.join(BASE_PATH, \"processed_data\")\n",
    "os.makedirs(PROCESSED_DATA_PATH, exist_ok=True)\n",
    "\n",
    "# Save the datasets\n",
    "# We'll save the SMOTE-balanced training set and the original test set\n",
    "X_train_smote.to_csv(os.path.join(PROCESSED_DATA_PATH, \"X_train_processed.csv\"), index=False)\n",
    "y_train_smote_multi.to_csv(os.path.join(PROCESSED_DATA_PATH, \"y_train_processed.csv\"), index=False)\n",
    "X_test.to_csv(os.path.join(PROCESSED_DATA_PATH, \"X_test_processed.csv\"), index=False)\n",
    "y_test_multi.to_csv(os.path.join(PROCESSED_DATA_PATH, \"y_test_processed.csv\"), index=False)\n",
    "\n",
    "print(f\"Processed data saved to: {PROCESSED_DATA_PATH}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
